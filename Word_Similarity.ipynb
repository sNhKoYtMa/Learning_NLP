{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fKVwiKGmIOOYxfmpZZEpx2VFrFxE8omP",
      "authorship_tag": "ABX9TyOFxmFiysKGrfCBjWJugPUO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPwVL3CRYU7v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Word Similarity\n",
        "内容：単語の類似度を測定<br>\n",
        "word2vecとfastTextでやってみる<br>\n",
        "実行環境：google colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjbfDSq_z2Ub",
        "colab_type": "text"
      },
      "source": [
        "# MeCab\n",
        "途中でMeCabが必要になるので，あらかじめ入れておく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mb-naazz25-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "cb07fdcb-c3be-4412-dae0-d40ca3641887"
      },
      "source": [
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null\n",
        "!echo mecab-config --dicdir\"/mecab-ipadic-neologd\""
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n",
            "mecab-config --dicdir/mecab-ipadic-neologd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC8ZAyNw0AHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "path_NEologd = 'd /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMbbK4Kp00L7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6eb177b7-8cbe-4733-c4a5-4651116eb4e0"
      },
      "source": [
        "m = MeCab.Tagger('-Owakati -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
        "wakati = m.parse('COVID-19のせいで就職氷河期になりそうでぴえんって感じ')\n",
        "print(wakati) # ちゃんとNEologdが使えていることを確認"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COVID-19 の せい で 就職氷河期 に なり そう で ぴえん って 感じ \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w2y8G4f1JUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7081c1a1-8f51-4dcc-8022-0f37a4a8eaa6"
      },
      "source": [
        "m = MeCab.Tagger(path)\n",
        "result = m.parse('猫')\n",
        "print(result)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "猫\t名詞,一般,*,*,*,*,猫,ネコ,ネコ\n",
            "EOS\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwGaXW2gzw1K",
        "colab_type": "text"
      },
      "source": [
        "# word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkyiBikTYI6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import word2vec\n",
        "import logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk93Omq7ZW0E",
        "colab_type": "code",
        "outputId": "f9afca5c-e2c2-477a-bb92-04c49e50d8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Colaboratory_file/NLP/neko_wakati.csv')\n",
        "df.head() # 確認"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw</th>\n",
              "      <th>preprocessed</th>\n",
              "      <th>wakati_mecab</th>\n",
              "      <th>wakati_sp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>吾輩《わがはい》は猫である。名前はまだ無い。</td>\n",
              "      <td>吾輩は猫である。名前はまだ無い。</td>\n",
              "      <td>猫 名前 無い</td>\n",
              "      <td>吾輩は猫である 。 名前はまだ 無い 。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>どこで生れたかとんと見当《けんとう》がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣い...</td>\n",
              "      <td>どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけ...</td>\n",
              "      <td>生れる 見当 つく 薄暗い する 泣く いた事 記憶 する 始める 人間 見る あと 聞く ...</td>\n",
              "      <td>どこ で 生れ た かと んと 見当 が つか ぬ 。 何でも 薄暗 い じ め じ め ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>この書生の掌の裏《うち》でしばらくはよい心持に坐っておったが、しばらくすると非常な速力で運...</td>\n",
              "      <td>この書生の掌の裏でしばらくはよい心持に坐っておったが、しばらくすると非常な速力で運転し始め...</td>\n",
              "      <td>書生 掌 裏 よい 心持 坐る おる する 非常 速力 運転 する 書生 動く 自分 動く ...</td>\n",
              "      <td>この 書生 の 掌 の 裏 で しばらく は よい 心持 に 坐って おった が 、 しば...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ふと気が付いて見ると書生はいない。たくさんおった兄弟が一｜疋《ぴき》も見えぬ。肝心《かんじ...</td>\n",
              "      <td>ふと気が付いて見ると書生はいない。たくさんおった兄弟が一疋も見えぬ。肝心の母親さえ姿を隠し...</td>\n",
              "      <td>気 付く 見る 書生 いる たくさん おる 兄弟 一疋 見える 肝心 母親 姿 隠す 上今 ...</td>\n",
              "      <td>ふと 気が 付いて 見ると 書生 は いない 。 た く さん おった 兄 弟 が一 疋 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ようやくの思いで笹原を這い出すと向うに大きな池がある。吾輩は池の前に坐ってどうしたらよかろ...</td>\n",
              "      <td>ようやくの思いで笹原を這い出すと向うに大きな池がある。吾輩は池の前に坐ってどうしたらよかろ...</td>\n",
              "      <td>思い 笹原 這い出す 向う 池 ある 池 前 坐る する よい 考える 見る 分別 出る す...</td>\n",
              "      <td>ようやく の 思い で 笹原 を 這 い 出すと 向う に 大きな 池 がある 。 吾輩は...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 raw  ...                                          wakati_sp\n",
              "0                            　吾輩《わがはい》は猫である。名前はまだ無い。  ...                               吾輩は猫である 。 名前はまだ 無い 。\n",
              "1  　どこで生れたかとんと見当《けんとう》がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣い...  ...   どこ で 生れ た かと んと 見当 が つか ぬ 。 何でも 薄暗 い じ め じ め ...\n",
              "2  　この書生の掌の裏《うち》でしばらくはよい心持に坐っておったが、しばらくすると非常な速力で運...  ...   この 書生 の 掌 の 裏 で しばらく は よい 心持 に 坐って おった が 、 しば...\n",
              "3  　ふと気が付いて見ると書生はいない。たくさんおった兄弟が一｜疋《ぴき》も見えぬ。肝心《かんじ...  ...   ふと 気が 付いて 見ると 書生 は いない 。 た く さん おった 兄 弟 が一 疋 ...\n",
              "4  　ようやくの思いで笹原を這い出すと向うに大きな池がある。吾輩は池の前に坐ってどうしたらよかろ...  ...   ようやく の 思い で 笹原 を 這 い 出すと 向う に 大きな 池 がある 。 吾輩は...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKjBNYiliDnt",
        "colab_type": "text"
      },
      "source": [
        "nanを取り除く作業"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ5kRKzNg1J5",
        "colab_type": "code",
        "outputId": "38adeeb6-5b69-47b9-e09d-bf885552c7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wakati_mecab_list = [row.wakati_mecab for index, row in df.iterrows()]\n",
        "nan_index = [i for i, wakati in enumerate(wakati_mecab_list) if str(wakati) == 'nan']\n",
        "len(nan_index) # 87個のnanが存在する\n",
        "for i in sorted(nan_index, reverse = True):\n",
        "    wakati_mecab_list.pop(i)\n",
        "# reverse = False だとnan_indexが昇順なので前から取り除かれて失敗しそう\n",
        "nan_index_new = [i for i, wakati in enumerate(wakati_mecab_list) if str(wakati) == 'nan']\n",
        "len(nan_index_new) # 確認"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3WCtSwsjz48",
        "colab_type": "text"
      },
      "source": [
        "分かち書きを二重listにする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHGhfU4khTD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wakati_mecab_split = [word.split(' ') for word in wakati_mecab_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTz-dM62j4C8",
        "colab_type": "text"
      },
      "source": [
        "word2vec学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysHzNUh6agWb",
        "colab_type": "code",
        "outputId": "098f4e3f-839b-4cf1-da4d-93b8c9e0e28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "model_trained = word2vec.Word2Vec(wakati_mecab_split,\n",
        "                         sg=1, # Skip-gram\n",
        "                         size=200, # 次元数\n",
        "                         min_count=5, # min_count回未満の単語を破棄\n",
        "                         window=5, # 文脈の最大単語数\n",
        "                         hs=1, # 階層ソフトマックス(ネガティブサンプリングするなら0)\n",
        "                         negative=5, # ネガティブサンプリング\n",
        "                         iter=50 # Epoch数\n",
        "                         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-19 08:29:47,295 : INFO : collecting all words and their counts\n",
            "2020-04-19 08:29:47,295 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-04-19 08:29:47,319 : INFO : collected 10083 word types from a corpus of 65937 raw words and 2168 sentences\n",
            "2020-04-19 08:29:47,320 : INFO : Loading a fresh vocabulary\n",
            "2020-04-19 08:29:47,335 : INFO : effective_min_count=5 retains 2422 unique words (24% of original 10083, drops 7661)\n",
            "2020-04-19 08:29:47,337 : INFO : effective_min_count=5 leaves 53142 word corpus (80% of original 65937, drops 12795)\n",
            "2020-04-19 08:29:47,352 : INFO : deleting the raw counts dictionary of 10083 items\n",
            "2020-04-19 08:29:47,354 : INFO : sample=0.001 downsamples 38 most-common words\n",
            "2020-04-19 08:29:47,355 : INFO : downsampling leaves estimated 43586 word corpus (82.0% of prior 53142)\n",
            "2020-04-19 08:29:47,360 : INFO : constructing a huffman tree from 2422 words\n",
            "2020-04-19 08:29:47,417 : INFO : built huffman tree with maximum node depth 13\n",
            "2020-04-19 08:29:47,423 : INFO : estimated required memory for 2422 words and 200 dimensions: 7508200 bytes\n",
            "2020-04-19 08:29:47,424 : INFO : resetting layer weights\n",
            "2020-04-19 08:29:47,952 : INFO : training model with 3 workers on 2422 vocabulary and 200 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
            "2020-04-19 08:29:48,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:48,496 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:48,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:48,530 : INFO : EPOCH - 1 : training on 65937 raw words (43556 effective words) took 0.6s, 76177 effective words/s\n",
            "2020-04-19 08:29:49,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:49,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:49,096 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:49,097 : INFO : EPOCH - 2 : training on 65937 raw words (43552 effective words) took 0.6s, 77896 effective words/s\n",
            "2020-04-19 08:29:49,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:49,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:49,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:49,672 : INFO : EPOCH - 3 : training on 65937 raw words (43671 effective words) took 0.6s, 77027 effective words/s\n",
            "2020-04-19 08:29:50,167 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:50,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:50,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:50,241 : INFO : EPOCH - 4 : training on 65937 raw words (43661 effective words) took 0.6s, 77893 effective words/s\n",
            "2020-04-19 08:29:50,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:50,783 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:50,810 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:50,811 : INFO : EPOCH - 5 : training on 65937 raw words (43550 effective words) took 0.6s, 77393 effective words/s\n",
            "2020-04-19 08:29:51,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:51,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:51,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:51,420 : INFO : EPOCH - 6 : training on 65937 raw words (43546 effective words) took 0.6s, 72548 effective words/s\n",
            "2020-04-19 08:29:51,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:51,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:51,989 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:51,990 : INFO : EPOCH - 7 : training on 65937 raw words (43603 effective words) took 0.6s, 77209 effective words/s\n",
            "2020-04-19 08:29:52,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:52,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:52,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:52,557 : INFO : EPOCH - 8 : training on 65937 raw words (43604 effective words) took 0.6s, 78108 effective words/s\n",
            "2020-04-19 08:29:53,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:53,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:53,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:53,120 : INFO : EPOCH - 9 : training on 65937 raw words (43615 effective words) took 0.6s, 78530 effective words/s\n",
            "2020-04-19 08:29:53,605 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:53,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:53,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:53,694 : INFO : EPOCH - 10 : training on 65937 raw words (43512 effective words) took 0.6s, 76931 effective words/s\n",
            "2020-04-19 08:29:54,198 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:54,211 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:54,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:54,263 : INFO : EPOCH - 11 : training on 65937 raw words (43524 effective words) took 0.6s, 77665 effective words/s\n",
            "2020-04-19 08:29:54,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:54,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:54,835 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:54,836 : INFO : EPOCH - 12 : training on 65937 raw words (43666 effective words) took 0.6s, 77276 effective words/s\n",
            "2020-04-19 08:29:55,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:55,356 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:55,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:55,392 : INFO : EPOCH - 13 : training on 65937 raw words (43550 effective words) took 0.5s, 79405 effective words/s\n",
            "2020-04-19 08:29:55,886 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:55,951 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:55,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:55,960 : INFO : EPOCH - 14 : training on 65937 raw words (43551 effective words) took 0.6s, 77804 effective words/s\n",
            "2020-04-19 08:29:56,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:56,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:56,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:56,535 : INFO : EPOCH - 15 : training on 65937 raw words (43634 effective words) took 0.6s, 76759 effective words/s\n",
            "2020-04-19 08:29:57,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:57,039 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:57,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:57,102 : INFO : EPOCH - 16 : training on 65937 raw words (43577 effective words) took 0.6s, 77926 effective words/s\n",
            "2020-04-19 08:29:57,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:57,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:57,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:57,670 : INFO : EPOCH - 17 : training on 65937 raw words (43631 effective words) took 0.6s, 77990 effective words/s\n",
            "2020-04-19 08:29:58,169 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:58,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:58,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:58,215 : INFO : EPOCH - 18 : training on 65937 raw words (43473 effective words) took 0.5s, 81049 effective words/s\n",
            "2020-04-19 08:29:58,713 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:58,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:58,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:58,783 : INFO : EPOCH - 19 : training on 65937 raw words (43590 effective words) took 0.6s, 77806 effective words/s\n",
            "2020-04-19 08:29:59,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:59,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:59,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:59,352 : INFO : EPOCH - 20 : training on 65937 raw words (43653 effective words) took 0.6s, 78149 effective words/s\n",
            "2020-04-19 08:29:59,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:29:59,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:29:59,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:29:59,918 : INFO : EPOCH - 21 : training on 65937 raw words (43672 effective words) took 0.6s, 78275 effective words/s\n",
            "2020-04-19 08:30:00,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:00,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:00,485 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:00,485 : INFO : EPOCH - 22 : training on 65937 raw words (43550 effective words) took 0.6s, 77772 effective words/s\n",
            "2020-04-19 08:30:00,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:01,041 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:01,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:01,051 : INFO : EPOCH - 23 : training on 65937 raw words (43621 effective words) took 0.6s, 78272 effective words/s\n",
            "2020-04-19 08:30:01,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:01,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:01,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:01,635 : INFO : EPOCH - 24 : training on 65937 raw words (43673 effective words) took 0.6s, 75762 effective words/s\n",
            "2020-04-19 08:30:02,133 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:02,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:02,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:02,203 : INFO : EPOCH - 25 : training on 65937 raw words (43615 effective words) took 0.6s, 77859 effective words/s\n",
            "2020-04-19 08:30:02,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:02,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:02,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:02,759 : INFO : EPOCH - 26 : training on 65937 raw words (43561 effective words) took 0.5s, 79370 effective words/s\n",
            "2020-04-19 08:30:03,256 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:03,275 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:03,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:03,328 : INFO : EPOCH - 27 : training on 65937 raw words (43613 effective words) took 0.6s, 77689 effective words/s\n",
            "2020-04-19 08:30:03,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:03,882 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:03,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:03,895 : INFO : EPOCH - 28 : training on 65937 raw words (43591 effective words) took 0.6s, 77964 effective words/s\n",
            "2020-04-19 08:30:04,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:04,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:04,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:04,451 : INFO : EPOCH - 29 : training on 65937 raw words (43603 effective words) took 0.5s, 79599 effective words/s\n",
            "2020-04-19 08:30:04,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:04,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:05,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:05,015 : INFO : EPOCH - 30 : training on 65937 raw words (43564 effective words) took 0.6s, 78419 effective words/s\n",
            "2020-04-19 08:30:05,520 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:05,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:05,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:05,574 : INFO : EPOCH - 31 : training on 65937 raw words (43587 effective words) took 0.6s, 79078 effective words/s\n",
            "2020-04-19 08:30:06,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:06,122 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:06,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:06,129 : INFO : EPOCH - 32 : training on 65937 raw words (43626 effective words) took 0.5s, 79741 effective words/s\n",
            "2020-04-19 08:30:06,579 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:06,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:06,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:06,693 : INFO : EPOCH - 33 : training on 65937 raw words (43605 effective words) took 0.6s, 78346 effective words/s\n",
            "2020-04-19 08:30:07,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:07,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:07,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:07,259 : INFO : EPOCH - 34 : training on 65937 raw words (43481 effective words) took 0.6s, 77860 effective words/s\n",
            "2020-04-19 08:30:07,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:07,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:07,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:07,828 : INFO : EPOCH - 35 : training on 65937 raw words (43617 effective words) took 0.6s, 77999 effective words/s\n",
            "2020-04-19 08:30:08,334 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:08,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:08,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:08,395 : INFO : EPOCH - 36 : training on 65937 raw words (43562 effective words) took 0.6s, 77922 effective words/s\n",
            "2020-04-19 08:30:08,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:08,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:08,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:08,957 : INFO : EPOCH - 37 : training on 65937 raw words (43474 effective words) took 0.6s, 78353 effective words/s\n",
            "2020-04-19 08:30:09,468 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:09,498 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:09,505 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:09,506 : INFO : EPOCH - 38 : training on 65937 raw words (43497 effective words) took 0.5s, 80588 effective words/s\n",
            "2020-04-19 08:30:10,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:10,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:10,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:10,086 : INFO : EPOCH - 39 : training on 65937 raw words (43499 effective words) took 0.6s, 75982 effective words/s\n",
            "2020-04-19 08:30:10,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:10,643 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:10,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:10,648 : INFO : EPOCH - 40 : training on 65937 raw words (43574 effective words) took 0.6s, 78647 effective words/s\n",
            "2020-04-19 08:30:11,125 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:11,191 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:11,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:11,203 : INFO : EPOCH - 41 : training on 65937 raw words (43691 effective words) took 0.5s, 79691 effective words/s\n",
            "2020-04-19 08:30:11,697 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:11,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:11,765 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:11,767 : INFO : EPOCH - 42 : training on 65937 raw words (43590 effective words) took 0.6s, 78440 effective words/s\n",
            "2020-04-19 08:30:12,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:12,361 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:12,366 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:12,367 : INFO : EPOCH - 43 : training on 65937 raw words (43600 effective words) took 0.6s, 74347 effective words/s\n",
            "2020-04-19 08:30:12,897 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:12,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:12,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:12,921 : INFO : EPOCH - 44 : training on 65937 raw words (43615 effective words) took 0.5s, 79741 effective words/s\n",
            "2020-04-19 08:30:13,386 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:13,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:13,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:13,470 : INFO : EPOCH - 45 : training on 65937 raw words (43605 effective words) took 0.5s, 80540 effective words/s\n",
            "2020-04-19 08:30:13,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:14,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:14,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:14,031 : INFO : EPOCH - 46 : training on 65937 raw words (43553 effective words) took 0.6s, 78913 effective words/s\n",
            "2020-04-19 08:30:14,508 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:14,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:14,580 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:14,581 : INFO : EPOCH - 47 : training on 65937 raw words (43596 effective words) took 0.5s, 80317 effective words/s\n",
            "2020-04-19 08:30:15,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:15,115 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:15,138 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:15,138 : INFO : EPOCH - 48 : training on 65937 raw words (43538 effective words) took 0.5s, 79244 effective words/s\n",
            "2020-04-19 08:30:15,651 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:15,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:15,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:15,728 : INFO : EPOCH - 49 : training on 65937 raw words (43574 effective words) took 0.6s, 74916 effective words/s\n",
            "2020-04-19 08:30:16,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-04-19 08:30:16,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-04-19 08:30:16,281 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-04-19 08:30:16,282 : INFO : EPOCH - 50 : training on 65937 raw words (43462 effective words) took 0.5s, 79550 effective words/s\n",
            "2020-04-19 08:30:16,283 : INFO : training on a 3296850 raw words (2179128 effective words) took 28.3s, 76919 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A0dXLloicRa",
        "colab_type": "text"
      },
      "source": [
        "word2vecのモデル保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH9ljXZsdU1W",
        "colab_type": "code",
        "outputId": "b8f0dfef-9e89-4396-f08c-3aaac5446ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "model_trained.save('/content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-19 08:30:58,801 : INFO : saving Word2Vec object under /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model, separately None\n",
            "2020-04-19 08:30:58,803 : INFO : not storing attribute vectors_norm\n",
            "2020-04-19 08:30:58,804 : INFO : not storing attribute cum_table\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-04-19 08:30:58,919 : INFO : saved /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K-fWPUUi3gx",
        "colab_type": "text"
      },
      "source": [
        "word2vecのモデル読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pALbFOjuZWuo",
        "colab_type": "code",
        "outputId": "1838e18b-0363-4816-9427-ca7ef2e12620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "model_w2v = word2vec.Word2Vec.load('/content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-19 08:31:00,962 : INFO : loading Word2Vec object from /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-04-19 08:31:01,050 : INFO : loading wv recursively from /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model.wv.* with mmap=None\n",
            "2020-04-19 08:31:01,051 : INFO : setting ignored attribute vectors_norm to None\n",
            "2020-04-19 08:31:01,056 : INFO : loading vocabulary recursively from /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model.vocabulary.* with mmap=None\n",
            "2020-04-19 08:31:01,057 : INFO : loading trainables recursively from /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model.trainables.* with mmap=None\n",
            "2020-04-19 08:31:01,058 : INFO : setting ignored attribute cum_table to None\n",
            "2020-04-19 08:31:01,059 : INFO : loaded /content/drive/My Drive/Colaboratory_file/NLP/neko_w2v_mecab.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8vTHLdpkTZZ",
        "colab_type": "text"
      },
      "source": [
        "類似度測定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcKnpQxdZWsh",
        "colab_type": "code",
        "outputId": "54fbcba3-2a83-4385-9f19-a68df12f725f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "print('=====word2vec trained by MeCab=====')\n",
        "s = input('類似度の計測をしたい単語を入力：')\n",
        "try:\n",
        "    word_low = s.lower()\n",
        "    m = MeCab.Tagger(path_NEologd)\n",
        "    word_ori = m.parse(s).split('\\t')[1].split(',')[6]\n",
        "    results = model_w2v.most_similar(positive=[word_ori], topn=20)\n",
        "    for i, result in enumerate(results):\n",
        "        print(i+1, '\\t', '{0:.5f}'.format(result[1]), ' ', result[0].lower())\n",
        "except KeyError:\n",
        "    print('{}が辞書の中に入っていない'.format(s))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====word2vec trained by MeCab=====\n",
            "類似度の計測をしたい単語を入力：猫\n",
            "1 \t 0.34151   属\n",
            "2 \t 0.32575   三毛\n",
            "3 \t 0.30698   鳴き声\n",
            "4 \t 0.29930   進化\n",
            "5 \t 0.29760   脳裏\n",
            "6 \t 0.29530   南無阿弥陀仏\n",
            "7 \t 0.29265   条件\n",
            "8 \t 0.28784   主人\n",
            "9 \t 0.27948   思う\n",
            "10 \t 0.27622   あら\n",
            "11 \t 0.27330   疑う\n",
            "12 \t 0.27066   する\n",
            "13 \t 0.27021   人間\n",
            "14 \t 0.26865   感ずる\n",
            "15 \t 0.26556   誇る\n",
            "16 \t 0.26288   下女\n",
            "17 \t 0.26260   同族\n",
            "18 \t 0.25715   生涯\n",
            "19 \t 0.25620   かご\n",
            "20 \t 0.25560   足\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7YVyvZNkGEL",
        "colab_type": "text"
      },
      "source": [
        "結果としては，小さいコーパスにしては悪くない気がする．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS37gOqYn90F",
        "colab_type": "text"
      },
      "source": [
        "## 類似度を測りたい語句がいくつかある場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG-rpokwZWrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_word_list = ['人間', '猫', '無能', '猫達','あいうえお']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGXvnVhKqIad",
        "colab_type": "text"
      },
      "source": [
        "word2vecで類似度計測をする関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-JhdsnIodHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def w2v_sim(word, num):\n",
        "    try:\n",
        "        results = model_w2v.most_similar(positive=[word], topn=num)\n",
        "        sim_words = [sim_word for sim_word, sim_cos in results]\n",
        "    except KeyError:\n",
        "        sim_words = [0]*num\n",
        "    return(sim_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B7-HDVcqvB_",
        "colab_type": "text"
      },
      "source": [
        "計測して，DataFrameを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yknSNd4BZWpR",
        "colab_type": "code",
        "outputId": "472d222b-712f-4c36-a5f0-d174ff5874cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "df_sim = pd.DataFrame()\n",
        "sim_level = 10\n",
        "for word in df_word_list:\n",
        "    df_sim[word] = w2v_sim(word, sim_level)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVLBbQgHkQqm",
        "colab_type": "code",
        "outputId": "11b5b296-9ef9-4c61-b6e0-45cb4d7a1746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "df_sim"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>人間</th>\n",
              "      <th>猫</th>\n",
              "      <th>無能</th>\n",
              "      <th>猫達</th>\n",
              "      <th>あいうえお</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>動物</td>\n",
              "      <td>属</td>\n",
              "      <td>全能</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>陥る</td>\n",
              "      <td>三毛</td>\n",
              "      <td>断定</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>衣服</td>\n",
              "      <td>鳴き声</td>\n",
              "      <td>上等</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>珍重</td>\n",
              "      <td>進化</td>\n",
              "      <td>失敗</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>運命</td>\n",
              "      <td>脳裏</td>\n",
              "      <td>断言</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>歴史</td>\n",
              "      <td>南無阿弥陀仏</td>\n",
              "      <td>栄</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>平等</td>\n",
              "      <td>条件</td>\n",
              "      <td>能力</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>人間らしい</td>\n",
              "      <td>主人</td>\n",
              "      <td>製造</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>意義</td>\n",
              "      <td>思う</td>\n",
              "      <td>灰色</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>能力</td>\n",
              "      <td>あら</td>\n",
              "      <td>疑う</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      人間       猫  無能  猫達  あいうえお\n",
              "0     動物       属  全能   0      0\n",
              "1     陥る      三毛  断定   0      0\n",
              "2     衣服     鳴き声  上等   0      0\n",
              "3     珍重      進化  失敗   0      0\n",
              "4     運命      脳裏  断言   0      0\n",
              "5     歴史  南無阿弥陀仏   栄   0      0\n",
              "6     平等      条件  能力   0      0\n",
              "7  人間らしい      主人  製造   0      0\n",
              "8     意義      思う  灰色   0      0\n",
              "9     能力      あら  疑う   0      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zVfHPMDrExZ",
        "colab_type": "text"
      },
      "source": [
        "計測できなかった場合は，0を入れておくことにした．<br>\n",
        "ここで重要なのは猫はできるが，猫達はできないという事．<br>\n",
        "こうする事で，カラムの消失を避ける事ができる．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCqGsyc5q9KT",
        "colab_type": "text"
      },
      "source": [
        "# fastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23-rgM5ZkQn6",
        "colab_type": "code",
        "outputId": "791bdec6-2357-4fc8-e086-9b5901bd76f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!sudo pip install ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 3768 (delta 35), reused 46 (delta 15), pack-reused 3684\u001b[K\n",
            "Receiving objects: 100% (3768/3768), 8.20 MiB | 5.55 MiB/s, done.\n",
            "Resolving deltas: 100% (2354/2354), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2872951 sha256=784e8a0054b80a470aca033e8f3070db89c619c59969a3f8be19231ca1096758\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x3iv8ikh/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa62Y_w6kQlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext as ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ta-VQU4zIg9",
        "colab_type": "text"
      },
      "source": [
        "csvにしないと上手くできなかった．<br>\n",
        "理由はよくわからない．．．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WCOy20_xyOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_wakati_mecab = pd.DataFrame(wakati_mecab_list, columns=['wakati'])\n",
        "df_wakati_mecab.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI49JhVIys2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colaboratory_file/NLP/neko_wakati_mecab.csv'\n",
        "df_wakati_mecab.to_csv(path, header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qDBHUWikQiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_trained = ft.train_unsupervised(path,\n",
        "                                      minn=2, # Ngram最小文字\n",
        "                                      maxn=8, # Ngram最大文字\n",
        "                                      dim=200, # 次元\n",
        "                                      epoch=50, # エポック\n",
        "                                      lr=0.1, # 学習率\n",
        "                                      thread=2) # 学習の並列処理数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wYQCmV912c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_trained.save_model('/content/drive/My Drive/Colaboratory_file/NLP/neko_ft_mecab.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJXZ6kxj1-lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "653d4808-036a-42da-b395-7d182f89ce76"
      },
      "source": [
        "model_ft = ft.load_model('/content/drive/My Drive/Colaboratory_file/NLP/neko_ft_mecab.bin')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIyqgAAnZWm7",
        "colab_type": "code",
        "outputId": "44000211-1e8a-4dc4-d8c1-f8bb140ccd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "print('=====fasttext trained by MeCab=====')\n",
        "s = input('類似度の計測をしたい単語を入力：')\n",
        "word_low = s.lower()\n",
        "m = MeCab.Tagger(path_NEologd)\n",
        "word_ori = m.parse(s).split('\\t')[1].split(',')[6]\n",
        "results = model_ft.get_nearest_neighbors(word_ori, k=20)\n",
        "for i, result in enumerate(results):\n",
        "    print(i+1, '\\t', '{0:.5f}'.format(result[0]), ' ', result[1].lower())"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====fasttext trained by MeCab=====\n",
            "類似度の計測をしたい単語を入力：猫\n",
            "1 \t 0.36584   人間\n",
            "2 \t 0.34531   する\n",
            "3 \t 0.32547   南無阿弥陀仏\n",
            "4 \t 0.32055   一疋\n",
            "5 \t 0.31664   ない\n",
            "6 \t 0.31560   動物\n",
            "7 \t 0.30543   進化\n",
            "8 \t 0.30425   思う\n",
            "9 \t 0.29995   見る\n",
            "10 \t 0.29411   鼠\n",
            "11 \t 0.28909   称する\n",
            "12 \t 0.28769   称す\n",
            "13 \t 0.28652   なる\n",
            "14 \t 0.27900   銭\n",
            "15 \t 0.27104   同族\n",
            "16 \t 0.27010   能力\n",
            "17 \t 0.26355   相互\n",
            "18 \t 0.26167   重んずる\n",
            "19 \t 0.25985   庸\n",
            "20 \t 0.25935   光景\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXrUHjO44EhW",
        "colab_type": "text"
      },
      "source": [
        "## 類似度を測りたい語句がいくつかある場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON8WY2zG4KBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_word_list = ['人間', '猫', '無能', '猫達','あいうえお']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1wklSwi3vq7",
        "colab_type": "text"
      },
      "source": [
        "fastTextを用いた類似度計測の関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Qzgko3ZWk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ft_sim(word, num):\n",
        "    results = model_ft.get_nearest_neighbors(word, k=num)\n",
        "    sim_words = [sim_word for sim_cos, sim_word in results]\n",
        "    return(sim_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY6bqt-M4PmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sim = pd.DataFrame()\n",
        "sim_level = 10\n",
        "for word in df_word_list:\n",
        "    df_sim[word] = ft_sim(word, sim_level)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8t065Ah4jn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "cd27a163-6bd7-4a05-8806-908dbcb7c293"
      },
      "source": [
        "df_sim"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>人間</th>\n",
              "      <th>猫</th>\n",
              "      <th>無能</th>\n",
              "      <th>猫達</th>\n",
              "      <th>あいうえお</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>する</td>\n",
              "      <td>人間</td>\n",
              "      <td>全能</td>\n",
              "      <td>友達</td>\n",
              "      <td>あがる</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ない</td>\n",
              "      <td>する</td>\n",
              "      <td>断言</td>\n",
              "      <td>発達</td>\n",
              "      <td>あら</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>猫</td>\n",
              "      <td>南無阿弥陀仏</td>\n",
              "      <td>証明</td>\n",
              "      <td>猫</td>\n",
              "      <td>あきらめる</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>出来る</td>\n",
              "      <td>一疋</td>\n",
              "      <td>あつかう</td>\n",
              "      <td>つらい</td>\n",
              "      <td>あした</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>云う</td>\n",
              "      <td>ない</td>\n",
              "      <td>断定</td>\n",
              "      <td>ただ今</td>\n",
              "      <td>呼吸</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>意義</td>\n",
              "      <td>動物</td>\n",
              "      <td>眼前</td>\n",
              "      <td>母堂</td>\n",
              "      <td>あばた</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>なる</td>\n",
              "      <td>進化</td>\n",
              "      <td>畠</td>\n",
              "      <td>活気</td>\n",
              "      <td>魚</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>無能</td>\n",
              "      <td>思う</td>\n",
              "      <td>手際</td>\n",
              "      <td>一疋</td>\n",
              "      <td>柿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ある</td>\n",
              "      <td>見る</td>\n",
              "      <td>勘弁</td>\n",
              "      <td>不道徳</td>\n",
              "      <td>あける</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>世の中</td>\n",
              "      <td>鼠</td>\n",
              "      <td>深夜</td>\n",
              "      <td>風邪</td>\n",
              "      <td>あく</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    人間       猫    無能   猫達  あいうえお\n",
              "0   する      人間    全能   友達    あがる\n",
              "1   ない      する    断言   発達     あら\n",
              "2    猫  南無阿弥陀仏    証明    猫  あきらめる\n",
              "3  出来る      一疋  あつかう  つらい    あした\n",
              "4   云う      ない    断定  ただ今     呼吸\n",
              "5   意義      動物    眼前   母堂    あばた\n",
              "6   なる      進化     畠   活気      魚\n",
              "7   無能      思う    手際   一疋      柿\n",
              "8   ある      見る    勘弁  不道徳    あける\n",
              "9  世の中       鼠    深夜   風邪     あく"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpVFh2sh4phB",
        "colab_type": "text"
      },
      "source": [
        "word2vecとは異なり，計測できないことが存在しない．<br>\n",
        "word2vecではできなかった猫達でもそれなりに測れている．<br>\n",
        "しかし，あいうえおは無理やり測った感が強いので，何も見ないと騙されそう．"
      ]
    }
  ]
}